# AI HR Interview Backend

Backend API for AI-powered HR interview system with live voice dialog and candidate evaluation.

## Features

- ðŸŽ¤ Live voice interview via WebSocket
- ðŸ¤– AI-powered candidate evaluation using multiple analyzers
- ðŸ“Š Modular analyzer architecture for speech and content analysis
- ðŸ—„ï¸ PostgreSQL database with async SQLAlchemy
- ðŸ³ Docker & Docker Compose for easy deployment
- ðŸ” JWT authentication
- ðŸ“ Comprehensive candidate evaluation reports

## AI

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ **DeepSeek**. Ð’ `.env` Ð·Ð°Ð´Ð°Ð¹Ñ‚Ðµ:

```bash
DEEPSEEK_API_KEY=your_deepseek_key_here
```

ÐšÐ»ÑŽÑ‡: [platform.deepseek.com](https://platform.deepseek.com)

## Architecture

The project follows Clean Architecture principles with modular analyzer system:

- **Analyzers**: Pluggable modules for different types of analysis (speech, content, behavior)
- **Services**: Business logic and orchestration
- **API**: FastAPI REST endpoints and WebSocket handlers
- **Models**: SQLAlchemy database models

## Quick Start

### Prerequisites

- Docker and Docker Compose
- DeepSeek API key

### Setup

1. Clone the repository and navigate to backend directory:
```bash
cd backend
```

2. Copy environment variables:
```bash
cp env.example .env
# Edit .env and set DEEPSEEK_API_KEY
```

3. Start services:
```bash
docker-compose up -d
```

4. Run database migrations (once database is ready):
```bash
docker-compose exec backend alembic upgrade head
```

5. Access the API:
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Health: http://localhost:8000/health

## Development

### Running without Docker

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Set up PostgreSQL database and configure `.env`

3. Run migrations:
```bash
alembic upgrade head
```

4. Start development server:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Smoke Test

ÐŸÐ¾ÑÐ»Ðµ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð´Ð° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒ smoke test Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð¾ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚Ð¸:

```bash
# Ð˜Ð· ÐºÐ¾Ñ€Ð½Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°:
python backend/smoke_test.py

# Ð˜Ð»Ð¸ Ð¸Ð· Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ backend:
cd backend && python smoke_test.py

# Ð˜Ð»Ð¸ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€Ð°Ð²Ð° Ð½Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ):
./backend/smoke_test.py
```

Smoke test Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚:
- âœ… Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð²ÑÐµÑ… Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
- âœ… ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
- âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…
- âœ… Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ AI ÑÐµÑ€Ð²Ð¸ÑÐ° (DeepSeek)
- âœ… Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ TTS ÑÐµÑ€Ð²Ð¸ÑÐ° (Google Cloud)
- âœ… Ð ÐµÐ³Ð¸ÑÑ‚Ñ€ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²
- âœ… Ð¡ÐµÑ€Ð²Ð¸Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸
- âœ… FastAPI Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¸ Ñ€Ð¾ÑƒÑ‚Ñ‹
- âœ… Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸

Ð¢ÐµÑÑ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐºÐ¾Ð´ Ð²Ñ‹Ñ…Ð¾Ð´Ð° 0 Ð¿Ñ€Ð¸ ÑƒÑÐ¿ÐµÑ…Ðµ, 1 Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ñ….

## Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ analyzers/          # Analyzer modules
â”‚   â”‚   â”œâ”€â”€ base.py        # Base analyzer class
â”‚   â”‚   â”œâ”€â”€ registry.py    # Analyzer registry
â”‚   â”‚   â”œâ”€â”€ speech/        # Speech analyzers
â”‚   â”‚   â”œâ”€â”€ content/       # Content analyzers
â”‚   â”‚   â””â”€â”€ behavior/      # Behavior analyzers
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”œâ”€â”€ schemas/           # Pydantic schemas
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”œâ”€â”€ websocket/         # WebSocket handlers
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ database.py        # Database setup
â”‚   â””â”€â”€ main.py            # FastAPI app
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ requirements.txt
```

## Adding New Analyzers

1. Create analyzer class inheriting from `BaseAnalyzer`:
```python
from app.analyzers.base import BaseAnalyzer, AnalysisResult

class MyAnalyzer(BaseAnalyzer):
    @property
    def name(self) -> str:
        return "my_analyzer"
    
    async def analyze(self, audio_data, transcript, metadata):
        # Your analysis logic
        return AnalysisResult(...)
```

2. Register it in the registry (see `app/analyzers/__init__.py`)

3. Add to configuration in `.env`:
```
ENABLED_ANALYZERS=...,my_analyzer
```

## Environment Variables

See `.env.example` for all available environment variables.

## API Documentation

Once running, visit http://localhost:8000/docs for interactive API documentation.

## License

MIT

